{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a19a764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4bc34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `GroundingDinoImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n",
      "Loading weights: 100%|██████████| 990/990 [00:05<00:00, 180.26it/s, Materializing param=model.text_projection.weight]                                                                           \n"
     ]
    }
   ],
   "source": [
    "model_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "device = Accelerator().device\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c8b72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(image, text_labels, processor, model):\n",
    "    print('text_labels: ', text_labels)\n",
    "    inputs = processor(images=image, text=text_labels, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    results = processor.post_process_grounded_object_detection(\n",
    "        outputs,\n",
    "        inputs.input_ids,\n",
    "        threshold=0.4,\n",
    "        text_threshold=0.3,\n",
    "        target_sizes=[image.size[::-1]]\n",
    "    )\n",
    "\n",
    "    result = results[0]\n",
    "    coordinates = []\n",
    "    for box, score, labels in zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"]):\n",
    "        box = [round(x, 2) for x in box.tolist()]\n",
    "        coordinates.append(box)\n",
    "        print(f\"Detected {labels} with confidence {round(score.item(), 3)} at location {box}\")\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "# run_model(image, text_labels, processor, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc468c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a bulb', 'a lady']]\n",
      "Detected a lady with confidence 0.806 at location [284.4, 127.31, 347.06, 307.8]\n",
      "Detected a bulb with confidence 0.485 at location [148.9, 12.48, 168.5, 36.74]\n"
     ]
    }
   ],
   "source": [
    "image_path = \"vegetables.jpg\"    # even with low quality, the model recognizes bulb, but not all BULBS\n",
    "image = Image.open(image_path)\n",
    "# Check for cats and remote controls\n",
    "# text_labels = [[\"a lady\"]]\n",
    "text_labels = [[\"a bulb\", \"a lady\"]]\n",
    "coordinates = run_model(image, text_labels, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a92b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a bulb', 'a lady', 'watermelons']]\n",
      "Detected a lady with confidence 0.598 at location [848.58, 382.67, 1044.35, 920.51]\n",
      "Detected a bulb with confidence 0.404 at location [448.62, 41.67, 504.18, 110.46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nanda\\myenv\\Lib\\site-packages\\transformers\\models\\grounding_dino\\processing_grounding_dino.py:91: FutureWarning: The key `labels` is will return integer ids in `GroundingDinoProcessor.post_process_grounded_object_detection` output since v4.51.0. Use `text_labels` instead to retrieve string object names.\n",
      "  warnings.warn(self.message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"vegetables_hig_quality.jpg\"    # even with low quality, the model recognizes bulb, but not all BULBS\n",
    "image = Image.open(image_path)\n",
    "text_labels = [[\"a bulb\", \"a lady\", \"watermelons\"]]\n",
    "coordinates = run_model(image, text_labels, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code provides an image but the transition from the blurred background to the clear foreground is not smooth\n",
    "def blur_outside_bbox_old(image_path, coords, blur_radius=10):\n",
    "    if len(coords) != 4:\n",
    "        raise ValueError(\"coords must be a list or tuple of [x1, y1, x2, y2].\")\n",
    "\n",
    "    x1, y1, x2, y2 = coords\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    blurred = image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "    bbox = (int(x1), int(y1), int(x2), int(y2))\n",
    "    region = image.crop(bbox)\n",
    "    blurred.paste(region, bbox)\n",
    "\n",
    "    root, ext = os.path.splitext(image_path)\n",
    "    output_path = f\"{root}_modified{ext}\"\n",
    "    blurred.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3869f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_outside_bbox(image_path, coords, blur_radius=10, feather_radius=15, blur_amount=1.0):\n",
    "    \"\"\"Blur everything outside coords with controllable blur strength and feathering.\"\"\"\n",
    "    if len(coords) != 4:\n",
    "        raise ValueError(\"coords must be a list or tuple of [x1, y1, x2, y2].\")\n",
    "    if not 0.0 <= blur_amount <= 1.0:\n",
    "        raise ValueError(\"blur_amount must be between 0 and 1.\")\n",
    "\n",
    "    x1, y1, x2, y2 = coords\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    blurred = image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "    if blur_amount < 1.0:\n",
    "        blurred = Image.blend(image, blurred, blur_amount)\n",
    "\n",
    "    bbox = (int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "    mask = Image.new(\"L\", image.size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.rectangle(bbox, fill=255)\n",
    "    if feather_radius > 0:\n",
    "        mask = mask.filter(ImageFilter.GaussianBlur(radius=feather_radius))\n",
    "\n",
    "    blended = Image.composite(image, blurred, mask)\n",
    "\n",
    "    root, ext = os.path.splitext(image_path)\n",
    "    output_path = f\"{root}_modified{ext}\"\n",
    "    blended.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b9749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a cat', 'a remote control']]\n",
      "Detected a cat with confidence 0.468 at location [344.4, 23.25, 637.28, 374.46]\n",
      "Detected a remote control with confidence 0.45 at location [38.56, 69.9, 176.79, 118.05]\n",
      "Detected a cat with confidence 0.435 at location [12.37, 51.98, 316.9, 472.5]\n"
     ]
    }
   ],
   "source": [
    "image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "# Check for cats and remote controls\n",
    "text_labels = [[\"a cat\", \"a remote control\"]]\n",
    "run_model(image, text_labels, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6714993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a bulb']]\n",
      "Detected a bulb with confidence 0.59 at location [450.25, 42.73, 501.94, 108.35]\n",
      "Detected a bulb with confidence 0.5 at location [681.66, 224.3, 710.03, 268.53]\n",
      "Detected a bulb with confidence 0.467 at location [716.31, 267.13, 740.77, 299.47]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vegetables_hig_quality_modified.jpg'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"vegetables_hig_quality.jpg\"\n",
    "image = Image.open(image_path)\n",
    "# Check for cats and remote controls\n",
    "# text_labels = [[\"a lady\"]]\n",
    "text_labels = [[\"a bulb\"]]\n",
    "coordinates = run_model(image, text_labels, processor, model)\n",
    "# this recognition is perfect\n",
    "\n",
    "blur_radius = 18  # Gaussian blur strength applied to the background\n",
    "feather_radius = 20  # controls softness of the transition edge\n",
    "blur_amount = 0.85  # 0 keeps background sharp, 1 uses the fully blurred background\n",
    "blur_outside_bbox(\n",
    "    image_path,\n",
    "    coordinates[0],\n",
    "    blur_radius=blur_radius,\n",
    "    feather_radius=feather_radius,\n",
    "    blur_amount=blur_amount,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "930666d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a bulb']]\n",
      "Detected a bulb with confidence 0.591 at location [149.73, 13.23, 167.74, 36.14]\n",
      "Detected a bulb with confidence 0.441 at location [227.09, 76.02, 236.69, 89.29]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vegetables_modified.jpg'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"vegetables.jpg\"\n",
    "image = Image.open(image_path)\n",
    "# Check for cats and remote controls\n",
    "# text_labels = [[\"a lady\"]]\n",
    "text_labels = [[\"a bulb\"]]\n",
    "coordinates = run_model(image, text_labels, processor, model)\n",
    "# this recognition is perfect\n",
    "\n",
    "blur_radius = 18  # Gaussian blur strength applied to the background\n",
    "feather_radius = 8  # controls softness of the transition edge, Low values (e.g., 0–5) keep the mask edge tight, so the blur starts almost immediately outside the box.\n",
    "blur_amount = 0.90  # 0 keeps background sharp, 1 uses the fully blurred background\n",
    "blur_outside_bbox(\n",
    "    image_path,\n",
    "    coordinates[0],\n",
    "    blur_radius=blur_radius,\n",
    "    feather_radius=feather_radius,\n",
    "    blur_amount=blur_amount,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5441f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['water melon']]\n",
      "Detected water melon with confidence 0.509 at location [207.06, 167.66, 276.57, 210.42]\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"vegetables.jpg\")\n",
    "# Check for cats and remote controls\n",
    "text_labels = [[\"water melon\"]]\n",
    "run_model(image, text_labels, processor, model)\n",
    "# WATERMELONS DID NOT WORK; BUT WATER MELON WORKED. THIS IS INTERESTING. \n",
    "# MAYBE THE MODEL CAN RECOGNIZE COMPOUND WORDS BETTER THAN SINGLE WORDS? \n",
    "# OR MAYBE IT JUST HAS A BETTER REPRESENTATION FOR WATER MELON THAN WATERMELON. THIS IS INTERESTING AND WORTH INVESTIGATING FURTHER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2c153ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['water melon', 'pikachu']]\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"family.jpg\")\n",
    "# Check for cats and remote controls\n",
    "text_labels = [[\"water melon\", \"pikachu\"]]\n",
    "run_model(image, text_labels, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1605ae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a man', 'a small girl']]\n",
      "Detected a man with confidence 0.557 at location [303.17, 153.06, 393.09, 387.56]\n",
      "Detected a small girl with confidence 0.43 at location [212.71, 131.34, 274.23, 266.34]\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"family.jpg\")\n",
    "# Check for cats and remote controls\n",
    "text_labels = [[\"a man\", \"a small girl\"]]\n",
    "run_model(image, text_labels, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfa037df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['a man', 'girl']]\n",
      "Detected a man with confidence 0.667 at location [303.39, 152.89, 392.7, 387.53]\n",
      "Detected girl with confidence 0.442 at location [209.92, 131.78, 275.62, 272.19]\n",
      "Detected girl with confidence 0.409 at location [205.61, 175.25, 288.67, 391.57]\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"family.jpg\")\n",
    "# Check for cats and remote controls\n",
    "text_labels = [[\"a man\", \"girl\"]]\n",
    "run_model(image, text_labels, processor, model)\n",
    "# prediction is wrong, one reason is image might be not clear, and second is adult is also considered a girl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9182235",
   "metadata": {},
   "source": [
    "### things to consider\n",
    "#### different images, images wiht different resolutions, multiple objects within an image, keywords given to the DINO model\n",
    "##### there is still difficulty for the model to identify the small objects in low resolution images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_labels:  [['orange tshirt kid']]\n",
      "Detected orange tshirt kid with confidence 0.564 at location [777.46, 230.21, 935.8, 405.11]\n",
      "Detected orange tshirt kid with confidence 0.587 at location [429.41, 243.01, 666.31, 435.45]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kids_football_modified.jpg'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"kids_football.jpg\"\n",
    "image = Image.open(image_path)\n",
    "# Check for cats and remote controls\n",
    "# text_labels = [[\"a lady\"]]\n",
    "text_labels = [[\"orange tshirt kid\"]]\n",
    "coordinates = run_model(image, text_labels, processor, model)\n",
    "# this recognition is perfect\n",
    "\n",
    "blur_radius = 18  # Gaussian blur strength applied to the background\n",
    "feather_radius = 20  # controls softness of the transition edge\n",
    "blur_amount = 0.85  # 0 keeps background sharp, 1 uses the fully blurred background\n",
    "blur_outside_bbox(\n",
    "    image_path,\n",
    "    coordinates[0],\n",
    "    blur_radius=blur_radius,\n",
    "    feather_radius=feather_radius,\n",
    "    blur_amount=blur_amount,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
